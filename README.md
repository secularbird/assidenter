# Assidenter

A Tauri 2 voice assistant application built with Vue.js that integrates:

- **WhisperLiveKit** for ASR (Automatic Speech Recognition)
- **Qwen 0.5** as the LLM (Large Language Model)
- **VoxCPM** for TTS (Text-to-Speech)
- **WebRTC VAD** for Voice Activity Detection

## Features

- ğŸ¤ Voice-based conversation with VAD (Voice Activity Detection)
- ğŸ§  AI-powered responses using Qwen 0.5B
- ğŸ”Š Text-to-speech output using VoxCPM
- âŒ¨ï¸ Text input support for hybrid interaction
- âš™ï¸ Configurable service endpoints
- ğŸŒ™ Modern dark theme UI

## Prerequisites

Before running the application, ensure you have the following services running:

### 1. WhisperLiveKit (ASR Server)
Default URL: `http://localhost:9090`

```bash
# Install and run WhisperLiveKit
# See: https://github.com/collabora/WhisperLiveKit
```

### 2. Qwen 0.5B (LLM Server)
Default URL: `http://localhost:8080`

```bash
# Run Qwen 0.5B with OpenAI-compatible API
# Can use llama.cpp, vLLM, or similar serving frameworks
```

### 3. VoxCPM (TTS Server)
Default URL: `http://localhost:5500`

```bash
# Install and run VoxCPM TTS server
# See: https://github.com/OpenBMB/VoxCPM
```

## Installation

### Install dependencies

```bash
npm install
```

### Development

```bash
npm run tauri dev
```

### Build

```bash
npm run tauri build
```

## Project Structure

```
assidenter/
â”œâ”€â”€ src/                    # Vue frontend source
â”‚   â”œâ”€â”€ App.vue            # Main app component
â”‚   â”œâ”€â”€ components/        # Vue components
â”‚   â”‚   â””â”€â”€ VoiceAssistant.vue
â”‚   â”œâ”€â”€ main.js            # Vue entry point
â”‚   â””â”€â”€ style.css          # Global styles
â”œâ”€â”€ src-tauri/             # Tauri/Rust backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ lib.rs         # Main Tauri app logic
â”‚   â”‚   â”œâ”€â”€ main.rs        # Entry point
â”‚   â”‚   â”œâ”€â”€ audio/         # Audio capture & VAD modules
â”‚   â”‚   â”‚   â”œâ”€â”€ capture.rs
â”‚   â”‚   â”‚   â”œâ”€â”€ vad.rs
â”‚   â”‚   â”‚   â””â”€â”€ mod.rs
â”‚   â”‚   â””â”€â”€ services/      # AI service integrations
â”‚   â”‚       â”œâ”€â”€ asr.rs     # WhisperLiveKit client
â”‚   â”‚       â”œâ”€â”€ llm.rs     # Qwen LLM client
â”‚   â”‚       â”œâ”€â”€ tts.rs     # VoxCPM TTS client
â”‚   â”‚       â””â”€â”€ mod.rs
â”‚   â”œâ”€â”€ Cargo.toml         # Rust dependencies
â”‚   â””â”€â”€ tauri.conf.json    # Tauri configuration
â”œâ”€â”€ package.json           # Node.js dependencies
â””â”€â”€ vite.config.js         # Vite configuration
```

## Usage

1. Start the required backend services (WhisperLiveKit, Qwen, VoxCPM)
2. Run the application with `npm run tauri dev`
3. Click the microphone button to start voice interaction
4. Speak your question - the VAD will detect when you start/stop speaking
5. Wait for the AI to process your speech and respond
6. Alternatively, type messages in the text input field

## Configuration

Click the âš™ï¸ button in the UI to configure service endpoints:

- **ASR Server**: WhisperLiveKit endpoint
- **LLM Server**: Qwen 0.5B API endpoint
- **TTS Server**: VoxCPM TTS endpoint

## Technical Details

### Voice Activity Detection (VAD)

The application uses WebRTC VAD for detecting speech in the audio stream:
- Analyzes audio in 30ms frames at 16kHz
- Requires 3 consecutive speech frames to trigger start
- Requires 10 consecutive silence frames to trigger end

### Audio Pipeline

1. **Capture**: Microphone input at 16kHz mono
2. **VAD**: Detect speech segments
3. **ASR**: Transcribe speech to text using WhisperLiveKit
4. **LLM**: Generate response using Qwen 0.5B
5. **TTS**: Synthesize speech using VoxCPM
6. **Playback**: Play audio response

## License

MIT
